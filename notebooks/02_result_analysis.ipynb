{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3bb9097f",
   "metadata": {},
   "source": [
    "# Result Analysis Notebook\n",
    "This notebooks is used to backtest the processed data and create a performance report\n",
    "\n",
    "## Key Activates:\n",
    "    1. Downlaod processed data from data/processed\n",
    "    2. Create and signals from signals.py\n",
    "    3. Run a Backtest from backtest.py\n",
    "    4. Generate a report from attribution.py and future talks about adding to the projects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841ff731",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import yaml\n",
    "import warnings\n",
    "from datetime import datetime, timedelta\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Add src directory to path to import custom modules\n",
    "sys.path.append('../src')\n",
    "from data_pipeline import download_raw_data, preprocess_data, save_data\n",
    "from signals import zscore_normalize, order_book_imbalance, etf_constituent_dislocation\n",
    "from backtest import (walk_forward_split, factor_neutralize, volatility_targeting, \n",
    "                     run_backtest, evaluate_performance, plot_performance)\n",
    "from attribution import (calculate_factor_exposures, attribute_pnl, \n",
    "                        generate_attribution_report, plot_attribution)\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0ca4db",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Load configuration from settings.yaml\n",
    "with open('../configs/settings.yaml', 'r') as file:\n",
    "    config = yaml.safe_load(file)\n",
    "\n",
    "print(\"Configuration loaded:\")\n",
    "print(f\"Tickers: {config['data']['tickers']}\")\n",
    "print(f\"Backtest period: {config['backtest']['start_date']} to {config['backtest']['end_date']}\")\n",
    "print(f\"Strategy type: {config['strategy']['type']}\")\n",
    "print(f\"Initial capital: ${config['backtest']['initial_capital']:,}\")\n",
    "\n",
    "# Extract configuration parameters\n",
    "tickers = config['data']['tickers']\n",
    "backtest_start = config['backtest']['start_date']\n",
    "backtest_end = config['backtest']['end_date']\n",
    "initial_capital = config['backtest']['initial_capital']\n",
    "commission = config['backtest']['commission']\n",
    "strategy_config = config['strategy']\n",
    "data_paths = config['paths']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ee5dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample processed data (since processed data may not exist yet)\n",
    "print(\"Creating sample processed data for backtesting...\")\n",
    "\n",
    "# Generate synthetic but realistic financial data\n",
    "np.random.seed(42)\n",
    "start_date = pd.to_datetime(backtest_start)\n",
    "end_date = pd.to_datetime(backtest_end)\n",
    "dates = pd.date_range(start=start_date, end=end_date, freq='D')\n",
    "\n",
    "# Remove weekends to simulate trading days only\n",
    "trading_days = dates[dates.weekday < 5]\n",
    "\n",
    "print(f\"Creating data for {len(trading_days)} trading days\")\n",
    "\n",
    "# Create sample processed data for each ticker\n",
    "processed_data = {}\n",
    "for ticker in tickers:\n",
    "    n_days = len(trading_days)\n",
    "    \n",
    "    # Generate realistic price data with drift and volatility\n",
    "    initial_price = np.random.uniform(50, 500)  # Random initial price\n",
    "    daily_returns = np.random.normal(0.0005, 0.02, n_days)  # 0.05% mean, 2% std daily\n",
    "    \n",
    "    # Add some autocorrelation to make returns more realistic\n",
    "    for i in range(1, len(daily_returns)):\n",
    "        daily_returns[i] += 0.1 * daily_returns[i-1]\n",
    "    \n",
    "    # Create cumulative prices\n",
    "    price_series = initial_price * np.exp(np.cumsum(daily_returns))\n",
    "    \n",
    "    # Create OHLCV data\n",
    "    data = pd.DataFrame(index=trading_days)\n",
    "    data['Close'] = price_series\n",
    "    data['Open'] = data['Close'].shift(1) * (1 + np.random.normal(0, 0.005, n_days))\n",
    "    data['High'] = np.maximum(data['Open'], data['Close']) * (1 + np.abs(np.random.normal(0, 0.01, n_days)))\n",
    "    data['Low'] = np.minimum(data['Open'], data['Close']) * (1 - np.abs(np.random.normal(0, 0.01, n_days)))\n",
    "    data['Volume'] = np.random.lognormal(15, 1, n_days).astype(int)  # Log-normal volume\n",
    "    \n",
    "    # Calculate returns\n",
    "    data['Returns'] = data['Close'].pct_change()\n",
    "    \n",
    "    # Add technical indicators\n",
    "    data['SMA_20'] = data['Close'].rolling(20).mean()\n",
    "    data['SMA_50'] = data['Close'].rolling(50).mean()\n",
    "    data['RSI'] = calculate_rsi(data['Close'], 14)\n",
    "    data['MACD'] = calculate_macd(data['Close'])\n",
    "    data['BB_Upper'], data['BB_Lower'] = calculate_bollinger_bands(data['Close'])\n",
    "    \n",
    "    # Add factor exposures (market factors)\n",
    "    data['Market_Factor'] = np.random.normal(0, 1, n_days)  # Market beta exposure\n",
    "    data['Size_Factor'] = np.random.normal(0, 0.5, n_days)  # Size factor exposure\n",
    "    data['Value_Factor'] = np.random.normal(0, 0.3, n_days)  # Value factor exposure\n",
    "    \n",
    "    # Clean data\n",
    "    data = data.dropna()\n",
    "    processed_data[ticker] = data\n",
    "\n",
    "def calculate_rsi(prices, window=14):\n",
    "    \"\"\"Calculate RSI\"\"\"\n",
    "    delta = prices.diff()\n",
    "    gain = (delta.where(delta > 0, 0)).rolling(window=window).mean()\n",
    "    loss = (-delta.where(delta < 0, 0)).rolling(window=window).mean()\n",
    "    rs = gain / loss\n",
    "    return 100 - (100 / (1 + rs))\n",
    "\n",
    "def calculate_macd(prices, fast=12, slow=26, signal=9):\n",
    "    \"\"\"Calculate MACD\"\"\"\n",
    "    exp1 = prices.ewm(span=fast).mean()\n",
    "    exp2 = prices.ewm(span=slow).mean()\n",
    "    return exp1 - exp2\n",
    "\n",
    "def calculate_bollinger_bands(prices, window=20, std_dev=2):\n",
    "    \"\"\"Calculate Bollinger Bands\"\"\"\n",
    "    sma = prices.rolling(window).mean()\n",
    "    std = prices.rolling(window).std()\n",
    "    return sma + (std * std_dev), sma - (std * std_dev)\n",
    "\n",
    "print(f\"Created processed data for {len(processed_data)} tickers\")\n",
    "for ticker, data in processed_data.items():\n",
    "    print(f\"{ticker}: {len(data)} observations from {data.index[0].date()} to {data.index[-1].date()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab250d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Signal Generation using signals.py\n",
    "print(\"Generating trading signals...\")\n",
    "\n",
    "# Combine all data for signal generation\n",
    "combined_returns = pd.DataFrame()\n",
    "combined_prices = pd.DataFrame()\n",
    "\n",
    "for ticker, data in processed_data.items():\n",
    "    combined_returns[ticker] = data['Returns']\n",
    "    combined_prices[ticker] = data['Close']\n",
    "\n",
    "# Generate mean reversion signals using z-score normalization\n",
    "lookback_period = strategy_config['lookback_period']\n",
    "entry_threshold = strategy_config['entry_threshold']\n",
    "exit_threshold = strategy_config['exit_threshold']\n",
    "\n",
    "signals = pd.DataFrame(index=combined_returns.index)\n",
    "\n",
    "print(f\"Using lookback period: {lookback_period} days\")\n",
    "print(f\"Entry threshold: {entry_threshold} standard deviations\")\n",
    "print(f\"Exit threshold: {exit_threshold} standard deviations\")\n",
    "\n",
    "for ticker in tickers:\n",
    "    if ticker in combined_prices.columns:\n",
    "        prices = combined_prices[ticker]\n",
    "        \n",
    "        # Calculate rolling statistics\n",
    "        rolling_mean = prices.rolling(window=lookback_period).mean()\n",
    "        rolling_std = prices.rolling(window=lookback_period).std()\n",
    "        z_score = (prices - rolling_mean) / rolling_std\n",
    "        \n",
    "        # Apply z-score normalization using custom function\n",
    "        try:\n",
    "            normalized_z = zscore_normalize(z_score.dropna())\n",
    "            # Realign with original index\n",
    "            z_score_normalized = pd.Series(index=z_score.index, dtype=float)\n",
    "            z_score_normalized[normalized_z.index] = normalized_z\n",
    "        except:\n",
    "            z_score_normalized = z_score\n",
    "        \n",
    "        # Generate signals\n",
    "        signal = pd.Series(index=prices.index, dtype=float)\n",
    "        signal[:] = 0  # Default to no position\n",
    "        \n",
    "        # Long signal when price is below lower threshold (oversold)\n",
    "        signal[z_score < -entry_threshold] = 1\n",
    "        # Short signal when price is above upper threshold (overbought)  \n",
    "        signal[z_score > entry_threshold] = -1\n",
    "        # Exit when z-score returns to normal range\n",
    "        signal[abs(z_score) < exit_threshold] = 0\n",
    "        \n",
    "        # Apply signal persistence (don't flip immediately)\n",
    "        signal = signal.fillna(method='ffill').fillna(0)\n",
    "        \n",
    "        signals[f'{ticker}_signal'] = signal\n",
    "        signals[f'{ticker}_zscore'] = z_score\n",
    "\n",
    "print(f\"Generated signals for {len([c for c in signals.columns if 'signal' in c])} assets\")\n",
    "\n",
    "# Signal quality analysis\n",
    "signal_stats = {}\n",
    "for ticker in tickers:\n",
    "    signal_col = f'{ticker}_signal'\n",
    "    if signal_col in signals.columns:\n",
    "        sig = signals[signal_col]\n",
    "        signal_stats[ticker] = {\n",
    "            'Long_signals': (sig == 1).sum(),\n",
    "            'Short_signals': (sig == -1).sum(),\n",
    "            'No_position': (sig == 0).sum(),\n",
    "            'Signal_frequency': (sig != 0).sum() / len(sig)\n",
    "        }\n",
    "\n",
    "signal_summary = pd.DataFrame(signal_stats).T\n",
    "print(\"\\nSignal Summary:\")\n",
    "print(signal_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb1186c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Signal Visualization\n",
    "print(\"Visualizing trading signals...\")\n",
    "\n",
    "# Create signal visualization for top 4 assets\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, ticker in enumerate(tickers[:4]):\n",
    "    ax = axes[i]\n",
    "    \n",
    "    # Plot price and z-score\n",
    "    price = combined_prices[ticker]\n",
    "    zscore = signals[f'{ticker}_zscore']\n",
    "    signal = signals[f'{ticker}_signal']\n",
    "    \n",
    "    # Create twin axis for z-score\n",
    "    ax2 = ax.twinx()\n",
    "    \n",
    "    # Plot price\n",
    "    ax.plot(price.index, price, 'b-', label='Price', linewidth=2)\n",
    "    ax.set_ylabel('Price ($)', color='b')\n",
    "    ax.tick_params(axis='y', labelcolor='b')\n",
    "    \n",
    "    # Plot z-score\n",
    "    ax2.plot(zscore.index, zscore, 'r-', alpha=0.7, label='Z-Score')\n",
    "    ax2.axhline(y=entry_threshold, color='orange', linestyle='--', alpha=0.7, label=f'Entry Threshold (±{entry_threshold})')\n",
    "    ax2.axhline(y=-entry_threshold, color='orange', linestyle='--', alpha=0.7)\n",
    "    ax2.axhline(y=0, color='gray', linestyle='-', alpha=0.5)\n",
    "    ax2.set_ylabel('Z-Score', color='r')\n",
    "    ax2.tick_params(axis='y', labelcolor='r')\n",
    "    \n",
    "    # Highlight signal periods\n",
    "    long_signals = signal == 1\n",
    "    short_signals = signal == -1\n",
    "    \n",
    "    if long_signals.any():\n",
    "        ax.scatter(price.index[long_signals], price[long_signals], \n",
    "                  color='green', marker='^', s=50, alpha=0.7, label='Long Signal')\n",
    "    if short_signals.any():\n",
    "        ax.scatter(price.index[short_signals], price[short_signals], \n",
    "                  color='red', marker='v', s=50, alpha=0.7, label='Short Signal')\n",
    "    \n",
    "    ax.set_title(f'{ticker} - Price and Trading Signals', fontweight='bold')\n",
    "    ax.legend(loc='upper left')\n",
    "    ax2.legend(loc='upper right')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Signal distribution analysis\n",
    "print(\"\\nSignal Distribution Analysis:\")\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Z-score distribution\n",
    "ax1 = axes[0]\n",
    "for ticker in tickers[:4]:\n",
    "    zscore = signals[f'{ticker}_zscore'].dropna()\n",
    "    ax1.hist(zscore, bins=30, alpha=0.6, label=ticker)\n",
    "ax1.axvline(x=entry_threshold, color='red', linestyle='--', label=f'Entry Threshold (±{entry_threshold})')\n",
    "ax1.axvline(x=-entry_threshold, color='red', linestyle='--')\n",
    "ax1.set_xlabel('Z-Score')\n",
    "ax1.set_ylabel('Frequency')\n",
    "ax1.set_title('Z-Score Distribution', fontweight='bold')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Signal frequency over time\n",
    "ax2 = axes[1]\n",
    "monthly_signals = signals[[c for c in signals.columns if 'signal' in c]].resample('M').apply(lambda x: (x != 0).sum())\n",
    "monthly_signals.plot(kind='bar', ax=ax2, alpha=0.7)\n",
    "ax2.set_title('Monthly Signal Frequency', fontweight='bold')\n",
    "ax2.set_xlabel('Month')\n",
    "ax2.set_ylabel('Number of Signals')\n",
    "ax2.tick_params(axis='x', rotation=45)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13251f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Portfolio Construction and Walk-Forward Analysis\n",
    "print(\"Setting up walk-forward backtesting framework...\")\n",
    "\n",
    "# Prepare data for backtesting using backtest.py functions\n",
    "# Combine all data into a single DataFrame for walk-forward analysis\n",
    "backtest_data = pd.DataFrame(index=combined_returns.index)\n",
    "\n",
    "# Add returns for all assets\n",
    "for ticker in tickers:\n",
    "    if ticker in combined_returns.columns:\n",
    "        backtest_data[f'{ticker}_return'] = combined_returns[ticker]\n",
    "        backtest_data[f'{ticker}_signal'] = signals[f'{ticker}_signal']\n",
    "\n",
    "# Add market factors for factor neutralization\n",
    "backtest_data['Market_Factor'] = np.random.normal(0, 1, len(backtest_data))\n",
    "backtest_data['Size_Factor'] = np.random.normal(0, 0.5, len(backtest_data))\n",
    "\n",
    "# Create portfolio returns based on signals\n",
    "print(\"Constructing portfolio based on signals...\")\n",
    "\n",
    "# Equal weight approach with signal-based allocation\n",
    "n_assets = len(tickers)\n",
    "max_positions = strategy_config['max_positions']\n",
    "\n",
    "portfolio_returns = pd.Series(index=backtest_data.index, dtype=float)\n",
    "portfolio_positions = pd.DataFrame(index=backtest_data.index, columns=tickers)\n",
    "\n",
    "for date in backtest_data.index[1:]:  # Start from second day\n",
    "    active_signals = {}\n",
    "    \n",
    "    # Get current signals for all assets\n",
    "    for ticker in tickers:\n",
    "        signal_col = f'{ticker}_signal'\n",
    "        if signal_col in backtest_data.columns:\n",
    "            signal = backtest_data.loc[date, signal_col]\n",
    "            if signal != 0:  # Non-zero signal\n",
    "                active_signals[ticker] = signal\n",
    "    \n",
    "    # Limit to max positions\n",
    "    if len(active_signals) > max_positions:\n",
    "        # Select strongest signals (furthest from zero)\n",
    "        sorted_signals = sorted(active_signals.items(), key=lambda x: abs(x[1]), reverse=True)\n",
    "        active_signals = dict(sorted_signals[:max_positions])\n",
    "    \n",
    "    # Calculate equal weights for active positions\n",
    "    if active_signals:\n",
    "        total_weight = sum(abs(signal) for signal in active_signals.values())\n",
    "        normalized_weights = {ticker: signal/total_weight for ticker, signal in active_signals.items()}\n",
    "        \n",
    "        # Calculate portfolio return for this period\n",
    "        period_return = 0\n",
    "        for ticker, weight in normalized_weights.items():\n",
    "            return_col = f'{ticker}_return'\n",
    "            if return_col in backtest_data.columns:\n",
    "                asset_return = backtest_data.loc[date, return_col]\n",
    "                if not pd.isna(asset_return):\n",
    "                    period_return += weight * asset_return\n",
    "                    portfolio_positions.loc[date, ticker] = weight\n",
    "        \n",
    "        portfolio_returns.loc[date] = period_return\n",
    "    else:\n",
    "        portfolio_returns.loc[date] = 0  # No positions\n",
    "\n",
    "# Clean and fill missing values\n",
    "portfolio_returns = portfolio_returns.fillna(0)\n",
    "portfolio_positions = portfolio_positions.fillna(0)\n",
    "\n",
    "print(f\"Portfolio construction complete. Average daily return: {portfolio_returns.mean():.4f}\")\n",
    "print(f\"Portfolio volatility (daily): {portfolio_returns.std():.4f}\")\n",
    "print(f\"Non-zero position days: {(portfolio_returns != 0).sum()} out of {len(portfolio_returns)}\")\n",
    "\n",
    "# Apply risk controls using backtest.py functions\n",
    "print(\"\\nApplying risk controls...\")\n",
    "\n",
    "# Create DataFrame for risk control functions\n",
    "risk_control_data = pd.DataFrame({\n",
    "    'Returns': portfolio_returns,\n",
    "    'Market_Factor': backtest_data['Market_Factor'],\n",
    "    'Size_Factor': backtest_data['Size_Factor']\n",
    "})\n",
    "\n",
    "# Apply factor neutralization\n",
    "try:\n",
    "    neutralized_data = factor_neutralize(risk_control_data, factors=['Market_Factor', 'Size_Factor'])\n",
    "    print(\"✓ Factor neutralization applied\")\n",
    "except Exception as e:\n",
    "    print(f\"⚠ Factor neutralization failed: {e}\")\n",
    "    neutralized_data = risk_control_data.copy()\n",
    "    neutralized_data['Neutralized Returns'] = neutralized_data['Returns']\n",
    "\n",
    "# Apply volatility targeting\n",
    "target_vol = 0.15  # 15% annualized target volatility\n",
    "try:\n",
    "    vol_targeted_data = volatility_targeting(neutralized_data, target_volatility=target_vol)\n",
    "    print(f\"✓ Volatility targeting applied (target: {target_vol:.1%})\")\n",
    "except Exception as e:\n",
    "    print(f\"⚠ Volatility targeting failed: {e}\")\n",
    "    vol_targeted_data = neutralized_data.copy()\n",
    "    vol_targeted_data['Volatility Targeted Returns'] = vol_targeted_data['Neutralized Returns']\n",
    "\n",
    "final_returns = vol_targeted_data['Volatility Targeted Returns'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99c901e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Backtest Execution and Performance Analysis\n",
    "print(\"Running backtest and performance analysis...\")\n",
    "\n",
    "# Run the backtest using backtest.py functions\n",
    "backtest_df = pd.DataFrame({\n",
    "    'Returns': portfolio_returns,\n",
    "    'Neutralized Returns': neutralized_data['Neutralized Returns'],\n",
    "    'Volatility Targeted Returns': final_returns\n",
    "})\n",
    "\n",
    "# Execute backtest\n",
    "portfolio_backtest = run_backtest(backtest_df, initial_capital=initial_capital)\n",
    "\n",
    "# Calculate performance metrics\n",
    "print(\"Calculating performance metrics...\")\n",
    "performance_metrics = evaluate_performance(portfolio_backtest)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"BACKTEST PERFORMANCE RESULTS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for metric, value in performance_metrics.items():\n",
    "    if isinstance(value, float):\n",
    "        if 'Return' in metric:\n",
    "            print(f\"{metric}: {value:.2%}\")\n",
    "        elif 'Drawdown' in metric:\n",
    "            print(f\"{metric}: {value:.2%}\")\n",
    "        else:\n",
    "            print(f\"{metric}: {value:.4f}\")\n",
    "    else:\n",
    "        print(f\"{metric}: {value}\")\n",
    "\n",
    "# Additional performance metrics\n",
    "returns_series = final_returns\n",
    "sharpe_ratio = (returns_series.mean() * 252) / (returns_series.std() * np.sqrt(252))\n",
    "sortino_ratio = (returns_series.mean() * 252) / (returns_series[returns_series < 0].std() * np.sqrt(252))\n",
    "calmar_ratio = (returns_series.mean() * 252) / abs(performance_metrics['Max Drawdown'])\n",
    "\n",
    "# Win rate analysis\n",
    "positive_returns = returns_series[returns_series > 0]\n",
    "negative_returns = returns_series[returns_series < 0]\n",
    "win_rate = len(positive_returns) / len(returns_series[returns_series != 0]) if len(returns_series[returns_series != 0]) > 0 else 0\n",
    "\n",
    "print(f\"\\nAdditional Metrics:\")\n",
    "print(f\"Sharpe Ratio: {sharpe_ratio:.3f}\")\n",
    "print(f\"Sortino Ratio: {sortino_ratio:.3f}\")\n",
    "print(f\"Calmar Ratio: {calmar_ratio:.3f}\")\n",
    "print(f\"Win Rate: {win_rate:.1%}\")\n",
    "print(f\"Average Win: {positive_returns.mean():.4f}\")\n",
    "print(f\"Average Loss: {negative_returns.mean():.4f}\")\n",
    "print(f\"Profit Factor: {positive_returns.sum() / abs(negative_returns.sum()):.2f}\")\n",
    "\n",
    "# Monthly and yearly performance breakdown\n",
    "monthly_returns = returns_series.resample('M').apply(lambda x: (1 + x).prod() - 1)\n",
    "yearly_returns = returns_series.resample('Y').apply(lambda x: (1 + x).prod() - 1)\n",
    "\n",
    "print(f\"\\nMonthly Statistics:\")\n",
    "print(f\"Best Month: {monthly_returns.max():.2%}\")\n",
    "print(f\"Worst Month: {monthly_returns.min():.2%}\")\n",
    "print(f\"Positive Months: {(monthly_returns > 0).sum()}/{len(monthly_returns)}\")\n",
    "\n",
    "if len(yearly_returns) > 1:\n",
    "    print(f\"\\nYearly Returns:\")\n",
    "    for year, ret in yearly_returns.items():\n",
    "        print(f\"{year.year}: {ret:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe0ee05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Performance Visualization\n",
    "print(\"Creating performance visualizations...\")\n",
    "\n",
    "# Create comprehensive performance charts\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# Chart 1: Cumulative Returns\n",
    "ax1 = axes[0, 0]\n",
    "cumulative_returns = (1 + returns_series).cumprod()\n",
    "portfolio_value = initial_capital * cumulative_returns\n",
    "\n",
    "ax1.plot(portfolio_value.index, portfolio_value, linewidth=2, label='Portfolio Value')\n",
    "ax1.axhline(y=initial_capital, color='gray', linestyle='--', alpha=0.7, label='Initial Capital')\n",
    "ax1.set_title('Portfolio Performance Over Time', fontweight='bold')\n",
    "ax1.set_ylabel('Portfolio Value ($)')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'${x:,.0f}'))\n",
    "\n",
    "# Chart 2: Drawdown\n",
    "ax2 = axes[0, 1]\n",
    "rolling_max = cumulative_returns.expanding().max()\n",
    "drawdown = (cumulative_returns - rolling_max) / rolling_max\n",
    "ax2.fill_between(drawdown.index, drawdown, 0, alpha=0.7, color='red')\n",
    "ax2.plot(drawdown.index, drawdown, color='darkred', linewidth=1)\n",
    "ax2.set_title('Portfolio Drawdown', fontweight='bold')\n",
    "ax2.set_ylabel('Drawdown (%)')\n",
    "ax2.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'{x:.1%}'))\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Chart 3: Rolling Sharpe Ratio\n",
    "ax3 = axes[1, 0]\n",
    "rolling_sharpe = returns_series.rolling(252).apply(\n",
    "    lambda x: (x.mean() * 252) / (x.std() * np.sqrt(252)) if x.std() > 0 else 0\n",
    ")\n",
    "ax3.plot(rolling_sharpe.index, rolling_sharpe, linewidth=2)\n",
    "ax3.axhline(y=1, color='green', linestyle='--', alpha=0.7, label='Sharpe = 1.0')\n",
    "ax3.axhline(y=0, color='gray', linestyle='-', alpha=0.5)\n",
    "ax3.set_title('Rolling 1-Year Sharpe Ratio', fontweight='bold')\n",
    "ax3.set_ylabel('Sharpe Ratio')\n",
    "ax3.legend()\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# Chart 4: Monthly Returns Heatmap\n",
    "ax4 = axes[1, 1]\n",
    "monthly_ret_pivot = monthly_returns.to_frame('Returns')\n",
    "monthly_ret_pivot['Year'] = monthly_ret_pivot.index.year\n",
    "monthly_ret_pivot['Month'] = monthly_ret_pivot.index.month\n",
    "monthly_heatmap = monthly_ret_pivot.pivot(index='Year', columns='Month', values='Returns')\n",
    "\n",
    "sns.heatmap(monthly_heatmap, annot=True, fmt='.1%', cmap='RdYlGn', center=0, \n",
    "           ax=ax4, cbar_kws={'label': 'Monthly Return'})\n",
    "ax4.set_title('Monthly Returns Heatmap', fontweight='bold')\n",
    "ax4.set_xlabel('Month')\n",
    "ax4.set_ylabel('Year')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Performance comparison chart\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12, 8))\n",
    "\n",
    "# Compare different return series\n",
    "raw_cumulative = (1 + portfolio_returns).cumprod() * initial_capital\n",
    "neutralized_cumulative = (1 + neutralized_data['Neutralized Returns']).cumprod() * initial_capital\n",
    "final_cumulative = (1 + final_returns).cumprod() * initial_capital\n",
    "\n",
    "ax.plot(raw_cumulative.index, raw_cumulative, label='Raw Strategy', alpha=0.8)\n",
    "ax.plot(neutralized_cumulative.index, neutralized_cumulative, label='Factor Neutralized', alpha=0.8)\n",
    "ax.plot(final_cumulative.index, final_cumulative, label='Vol Targeted (Final)', alpha=0.8, linewidth=2)\n",
    "\n",
    "# Add benchmark (buy and hold equal weight)\n",
    "benchmark_returns = combined_returns.mean(axis=1)\n",
    "benchmark_cumulative = (1 + benchmark_returns).cumprod() * initial_capital\n",
    "ax.plot(benchmark_cumulative.index, benchmark_cumulative, label='Equal Weight Benchmark', \n",
    "        color='gray', alpha=0.7, linestyle='--')\n",
    "\n",
    "ax.set_title('Strategy Performance Comparison', fontweight='bold', fontsize=14)\n",
    "ax.set_ylabel('Portfolio Value ($)')\n",
    "ax.set_xlabel('Date')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'${x:,.0f}'))\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Risk-Return scatter\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 8))\n",
    "\n",
    "strategies = {\n",
    "    'Raw Strategy': portfolio_returns,\n",
    "    'Factor Neutralized': neutralized_data['Neutralized Returns'],\n",
    "    'Vol Targeted': final_returns,\n",
    "    'Benchmark': benchmark_returns\n",
    "}\n",
    "\n",
    "for name, returns in strategies.items():\n",
    "    annual_return = returns.mean() * 252\n",
    "    annual_vol = returns.std() * np.sqrt(252)\n",
    "    ax.scatter(annual_vol, annual_return, s=100, label=name, alpha=0.8)\n",
    "    ax.annotate(name, (annual_vol, annual_return), xytext=(5, 5), \n",
    "               textcoords='offset points', fontsize=10)\n",
    "\n",
    "ax.set_xlabel('Annualized Volatility')\n",
    "ax.set_ylabel('Annualized Return')\n",
    "ax.set_title('Risk-Return Profile', fontweight='bold', fontsize=14)\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.xaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'{x:.1%}'))\n",
    "ax.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'{x:.1%}'))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c2106d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Attribution Analysis using attribution.py\n",
    "print(\"Performing attribution analysis...\")\n",
    "\n",
    "# Prepare data for attribution analysis\n",
    "# Create factor returns for attribution\n",
    "factor_returns = pd.DataFrame(index=returns_series.index)\n",
    "factor_returns['Market'] = backtest_data['Market_Factor'] * 0.001  # Convert to return scale\n",
    "factor_returns['Size'] = backtest_data['Size_Factor'] * 0.0005\n",
    "factor_returns['Momentum'] = returns_series.rolling(20).mean()  # Momentum factor\n",
    "factor_returns = factor_returns.fillna(0)\n",
    "\n",
    "# Asset returns for attribution (individual asset contributions)\n",
    "asset_returns = pd.DataFrame()\n",
    "for ticker in tickers:\n",
    "    return_col = f'{ticker}_return'\n",
    "    if return_col in backtest_data.columns:\n",
    "        asset_returns[ticker] = backtest_data[return_col]\n",
    "\n",
    "asset_returns = asset_returns.fillna(0)\n",
    "\n",
    "print(f\"Running attribution analysis for {len(asset_returns.columns)} assets and {len(factor_returns.columns)} factors\")\n",
    "\n",
    "try:\n",
    "    # Calculate factor exposures\n",
    "    exposures = calculate_factor_exposures(asset_returns, factor_returns)\n",
    "    print(\"✓ Factor exposures calculated\")\n",
    "    print(\"\\nFactor Exposures:\")\n",
    "    print(exposures.round(3))\n",
    "    \n",
    "    # Calculate attributed PnL\n",
    "    attributed_pnl = attribute_pnl(asset_returns, factor_returns, exposures)\n",
    "    print(\"✓ PnL attribution calculated\")\n",
    "    \n",
    "    # Generate attribution report\n",
    "    attribution_report = generate_attribution_report(attributed_pnl)\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"ATTRIBUTION ANALYSIS REPORT\")\n",
    "    print(\"=\"*50)\n",
    "    print(attribution_report)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Attribution analysis failed: {e}\")\n",
    "    print(\"Creating simplified attribution analysis...\")\n",
    "    \n",
    "    # Simplified attribution - contribution by asset\n",
    "    portfolio_weights = portfolio_positions.abs().div(portfolio_positions.abs().sum(axis=1), axis=0)\n",
    "    portfolio_weights = portfolio_weights.fillna(0)\n",
    "    \n",
    "    asset_contributions = {}\n",
    "    for ticker in tickers:\n",
    "        if ticker in asset_returns.columns and ticker in portfolio_weights.columns:\n",
    "            contribution = (portfolio_weights[ticker] * asset_returns[ticker]).fillna(0)\n",
    "            asset_contributions[ticker] = {\n",
    "                'Total_Contribution': contribution.sum(),\n",
    "                'Average_Weight': portfolio_weights[ticker].mean(),\n",
    "                'Contribution_Volatility': contribution.std()\n",
    "            }\n",
    "    \n",
    "    attribution_simple = pd.DataFrame(asset_contributions).T\n",
    "    print(\"\\nSimplified Asset Attribution:\")\n",
    "    print(attribution_simple.round(4))\n",
    "\n",
    "# Attribution visualization\n",
    "if 'attributed_pnl' in locals():\n",
    "    print(\"Creating attribution visualizations...\")\n",
    "    \n",
    "    # Plot attribution for top contributing assets\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    \n",
    "    # Top 4 assets by total attributed PnL\n",
    "    top_assets = attributed_pnl.sum().abs().nlargest(4).index\n",
    "    \n",
    "    for i, asset in enumerate(top_assets):\n",
    "        ax = axes[i//2, i%2]\n",
    "        cumulative_attribution = attributed_pnl[asset].cumsum()\n",
    "        ax.plot(cumulative_attribution.index, cumulative_attribution, linewidth=2)\n",
    "        ax.set_title(f'Cumulative Attribution - {asset}', fontweight='bold')\n",
    "        ax.set_ylabel('Cumulative Attributed PnL')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        ax.axhline(y=0, color='gray', linestyle='-', alpha=0.5)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Factor exposure analysis\n",
    "if 'exposures' in locals():\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(12, 8))\n",
    "    \n",
    "    # Heatmap of factor exposures\n",
    "    sns.heatmap(exposures, annot=True, cmap='RdBu_r', center=0, \n",
    "               ax=ax, cbar_kws={'label': 'Factor Exposure'})\n",
    "    ax.set_title('Asset Factor Exposures', fontweight='bold', fontsize=14)\n",
    "    ax.set_xlabel('Assets')\n",
    "    ax.set_ylabel('Factors')\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    # Factor contribution over time\n",
    "    factor_contribution = pd.DataFrame(index=factor_returns.index)\n",
    "    for factor in factor_returns.columns:\n",
    "        total_exposure = exposures[factor].sum()\n",
    "        factor_contribution[factor] = factor_returns[factor] * total_exposure\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 1, figsize=(12, 8))\n",
    "    factor_contribution.cumsum().plot(ax=ax, linewidth=2)\n",
    "    ax.set_title('Cumulative Factor Contributions', fontweight='bold', fontsize=14)\n",
    "    ax.set_ylabel('Cumulative Contribution')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac75b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Risk Analysis and Stress Testing\n",
    "print(\"Performing risk analysis and stress testing...\")\n",
    "\n",
    "# Calculate comprehensive risk metrics\n",
    "risk_metrics = {}\n",
    "\n",
    "# Value at Risk (VaR) and Expected Shortfall (ES)\n",
    "for confidence in [0.95, 0.99]:\n",
    "    var = np.percentile(returns_series, (1-confidence)*100)\n",
    "    es = returns_series[returns_series <= var].mean()\n",
    "    risk_metrics[f'VaR_{int(confidence*100)}'] = var\n",
    "    risk_metrics[f'ES_{int(confidence*100)}'] = es\n",
    "\n",
    "# Tail risk metrics\n",
    "risk_metrics['Skewness'] = returns_series.skew()\n",
    "risk_metrics['Kurtosis'] = returns_series.kurtosis()\n",
    "risk_metrics['Tail_Ratio'] = np.percentile(returns_series, 95) / abs(np.percentile(returns_series, 5))\n",
    "\n",
    "# Maximum consecutive losses\n",
    "consecutive_losses = 0\n",
    "max_consecutive = 0\n",
    "for ret in returns_series:\n",
    "    if ret < 0:\n",
    "        consecutive_losses += 1\n",
    "        max_consecutive = max(max_consecutive, consecutive_losses)\n",
    "    else:\n",
    "        consecutive_losses = 0\n",
    "\n",
    "risk_metrics['Max_Consecutive_Losses'] = max_consecutive\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"RISK ANALYSIS REPORT\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "for metric, value in risk_metrics.items():\n",
    "    if 'VaR' in metric or 'ES' in metric:\n",
    "        print(f\"{metric}: {value:.4f} ({value:.2%})\")\n",
    "    elif metric in ['Skewness', 'Kurtosis', 'Tail_Ratio']:\n",
    "        print(f\"{metric}: {value:.3f}\")\n",
    "    else:\n",
    "        print(f\"{metric}: {value}\")\n",
    "\n",
    "# Stress testing scenarios\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"STRESS TESTING SCENARIOS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "stress_scenarios = {\n",
    "    'Market_Crash_2008': -0.20,    # -20% market shock\n",
    "    'Flash_Crash': -0.10,          # -10% sudden drop\n",
    "    'High_Volatility': 0.05,       # +5% with high vol\n",
    "    'Liquidity_Crisis': -0.15      # -15% with liquidity issues\n",
    "}\n",
    "\n",
    "for scenario_name, shock in stress_scenarios.items():\n",
    "    # Apply shock to portfolio\n",
    "    stressed_return = returns_series.mean() + shock\n",
    "    stressed_portfolio_value = initial_capital * (1 + stressed_return)\n",
    "    loss_amount = initial_capital - stressed_portfolio_value\n",
    "    loss_percentage = loss_amount / initial_capital\n",
    "    \n",
    "    print(f\"{scenario_name}:\")\n",
    "    print(f\"  Shock Applied: {shock:.1%}\")\n",
    "    print(f\"  Portfolio Value: ${stressed_portfolio_value:,.0f}\")\n",
    "    print(f\"  Loss Amount: ${loss_amount:,.0f}\")\n",
    "    print(f\"  Loss Percentage: {loss_percentage:.2%}\")\n",
    "    print()\n",
    "\n",
    "# Risk visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# Returns distribution with VaR\n",
    "ax1 = axes[0, 0]\n",
    "ax1.hist(returns_series, bins=50, alpha=0.7, density=True, edgecolor='black')\n",
    "ax1.axvline(x=risk_metrics['VaR_95'], color='red', linestyle='--', \n",
    "           label=f\"VaR 95%: {risk_metrics['VaR_95']:.3f}\")\n",
    "ax1.axvline(x=risk_metrics['VaR_99'], color='darkred', linestyle='--', \n",
    "           label=f\"VaR 99%: {risk_metrics['VaR_99']:.3f}\")\n",
    "ax1.set_title('Returns Distribution with VaR', fontweight='bold')\n",
    "ax1.set_xlabel('Daily Returns')\n",
    "ax1.set_ylabel('Density')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Rolling volatility\n",
    "ax2 = axes[0, 1]\n",
    "rolling_vol = returns_series.rolling(30).std() * np.sqrt(252)\n",
    "ax2.plot(rolling_vol.index, rolling_vol, linewidth=2)\n",
    "ax2.axhline(y=rolling_vol.mean(), color='red', linestyle='--', \n",
    "           label=f'Average: {rolling_vol.mean():.1%}')\n",
    "ax2.set_title('30-Day Rolling Volatility (Annualized)', fontweight='bold')\n",
    "ax2.set_ylabel('Volatility')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'{x:.1%}'))\n",
    "\n",
    "# Q-Q plot for normality check\n",
    "ax3 = axes[1, 0]\n",
    "from scipy import stats\n",
    "stats.probplot(returns_series.dropna(), dist=\"norm\", plot=ax3)\n",
    "ax3.set_title('Q-Q Plot (Normal Distribution)', fontweight='bold')\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# Underwater plot (drawdown duration)\n",
    "ax4 = axes[1, 1]\n",
    "cumulative = (1 + returns_series).cumprod()\n",
    "running_max = cumulative.expanding().max()\n",
    "underwater = (cumulative - running_max) / running_max\n",
    "ax4.fill_between(underwater.index, underwater, 0, alpha=0.7, color='red')\n",
    "ax4.set_title('Underwater Plot (Drawdown Duration)', fontweight='bold')\n",
    "ax4.set_ylabel('Drawdown')\n",
    "ax4.grid(True, alpha=0.3)\n",
    "ax4.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'{x:.1%}'))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e45b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 8: Position Analysis and Trade Analytics\n",
    "print(\"Analyzing positions and trade characteristics...\")\n",
    "\n",
    "# Position analysis\n",
    "position_analysis = {}\n",
    "\n",
    "for ticker in tickers:\n",
    "    if ticker in portfolio_positions.columns:\n",
    "        positions = portfolio_positions[ticker]\n",
    "        non_zero_positions = positions[positions != 0]\n",
    "        \n",
    "        if len(non_zero_positions) > 0:\n",
    "            position_analysis[ticker] = {\n",
    "                'Total_Trades': len(non_zero_positions),\n",
    "                'Average_Position_Size': non_zero_positions.abs().mean(),\n",
    "                'Max_Position_Size': non_zero_positions.abs().max(),\n",
    "                'Long_Positions': (non_zero_positions > 0).sum(),\n",
    "                'Short_Positions': (non_zero_positions < 0).sum(),\n",
    "                'Position_Days': len(non_zero_positions),\n",
    "                'Position_Frequency': len(non_zero_positions) / len(positions)\n",
    "            }\n",
    "\n",
    "position_df = pd.DataFrame(position_analysis).T\n",
    "print(\"\\nPosition Analysis by Asset:\")\n",
    "print(position_df.round(4))\n",
    "\n",
    "# Trade duration analysis\n",
    "print(\"\\nTrade Duration Analysis:\")\n",
    "trade_durations = []\n",
    "current_position = 0\n",
    "trade_start = None\n",
    "\n",
    "for date, positions_row in portfolio_positions.iterrows():\n",
    "    total_position = positions_row.abs().sum()\n",
    "    \n",
    "    if total_position > 0 and current_position == 0:\n",
    "        # New trade started\n",
    "        trade_start = date\n",
    "        current_position = total_position\n",
    "    elif total_position == 0 and current_position > 0:\n",
    "        # Trade ended\n",
    "        if trade_start is not None:\n",
    "            duration = (date - trade_start).days\n",
    "            trade_durations.append(duration)\n",
    "        current_position = 0\n",
    "\n",
    "if trade_durations:\n",
    "    print(f\"Total Trades: {len(trade_durations)}\")\n",
    "    print(f\"Average Trade Duration: {np.mean(trade_durations):.1f} days\")\n",
    "    print(f\"Median Trade Duration: {np.median(trade_durations):.1f} days\")\n",
    "    print(f\"Min Trade Duration: {min(trade_durations)} days\")\n",
    "    print(f\"Max Trade Duration: {max(trade_durations)} days\")\n",
    "\n",
    "# Turnover analysis\n",
    "daily_turnover = portfolio_positions.diff().abs().sum(axis=1)\n",
    "average_turnover = daily_turnover.mean()\n",
    "annual_turnover = average_turnover * 252\n",
    "\n",
    "print(f\"\\nTurnover Analysis:\")\n",
    "print(f\"Average Daily Turnover: {average_turnover:.4f}\")\n",
    "print(f\"Estimated Annual Turnover: {annual_turnover:.2f}x\")\n",
    "\n",
    "# Transaction cost impact\n",
    "transaction_costs = daily_turnover * commission  # Apply commission rate\n",
    "net_returns_after_costs = returns_series - transaction_costs\n",
    "cumulative_cost_impact = transaction_costs.cumsum()\n",
    "\n",
    "cost_impact_metrics = {\n",
    "    'Total_Transaction_Costs': transaction_costs.sum(),\n",
    "    'Average_Daily_Costs': transaction_costs.mean(),\n",
    "    'Cost_Impact_on_Returns': (returns_series.mean() - net_returns_after_costs.mean()) * 252,\n",
    "    'Cost_as_Percent_of_Returns': (transaction_costs.sum() / returns_series.sum()) if returns_series.sum() != 0 else 0\n",
    "}\n",
    "\n",
    "print(f\"\\nTransaction Cost Analysis:\")\n",
    "for metric, value in cost_impact_metrics.items():\n",
    "    if 'Percent' in metric:\n",
    "        print(f\"{metric}: {value:.2%}\")\n",
    "    elif 'Impact' in metric or 'Daily' in metric:\n",
    "        print(f\"{metric}: {value:.4f}\")\n",
    "    else:\n",
    "        print(f\"{metric}: {value:.6f}\")\n",
    "\n",
    "# Position and trade visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# Position concentration over time\n",
    "ax1 = axes[0, 0]\n",
    "position_concentration = portfolio_positions.abs().sum(axis=1)\n",
    "ax1.plot(position_concentration.index, position_concentration, linewidth=2)\n",
    "ax1.set_title('Total Position Concentration Over Time', fontweight='bold')\n",
    "ax1.set_ylabel('Total Absolute Positions')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Position distribution by asset\n",
    "ax2 = axes[0, 1]\n",
    "if len(position_df) > 0:\n",
    "    position_df['Position_Days'].plot(kind='bar', ax=ax2, alpha=0.7)\n",
    "    ax2.set_title('Position Days by Asset', fontweight='bold')\n",
    "    ax2.set_ylabel('Number of Days with Positions')\n",
    "    ax2.tick_params(axis='x', rotation=45)\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Trade duration histogram\n",
    "ax3 = axes[1, 0]\n",
    "if trade_durations:\n",
    "    ax3.hist(trade_durations, bins=20, alpha=0.7, edgecolor='black')\n",
    "    ax3.axvline(x=np.mean(trade_durations), color='red', linestyle='--', \n",
    "               label=f'Mean: {np.mean(trade_durations):.1f} days')\n",
    "    ax3.set_title('Trade Duration Distribution', fontweight='bold')\n",
    "    ax3.set_xlabel('Duration (days)')\n",
    "    ax3.set_ylabel('Frequency')\n",
    "    ax3.legend()\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# Cumulative transaction costs\n",
    "ax4 = axes[1, 1]\n",
    "ax4.plot(cumulative_cost_impact.index, cumulative_cost_impact, \n",
    "         linewidth=2, color='red', label='Cumulative Costs')\n",
    "ax4_twin = ax4.twinx()\n",
    "ax4_twin.plot(returns_series.cumsum().index, returns_series.cumsum(), \n",
    "              linewidth=2, color='blue', alpha=0.7, label='Cumulative Returns')\n",
    "ax4.set_title('Transaction Costs vs Returns', fontweight='bold')\n",
    "ax4.set_ylabel('Cumulative Transaction Costs', color='red')\n",
    "ax4_twin.set_ylabel('Cumulative Returns', color='blue')\n",
    "ax4.legend(loc='upper left')\n",
    "ax4_twin.legend(loc='upper right')\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1866cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 9: Generate Comprehensive Report and Save Results\n",
    "print(\"Generating comprehensive performance report...\")\n",
    "\n",
    "# Create final performance summary\n",
    "final_report = {\n",
    "    'Strategy_Overview': {\n",
    "        'Strategy_Type': strategy_config['type'],\n",
    "        'Backtest_Period': f\"{backtest_start} to {backtest_end}\",\n",
    "        'Number_of_Assets': len(tickers),\n",
    "        'Initial_Capital': initial_capital,\n",
    "        'Final_Portfolio_Value': portfolio_backtest['Portfolio Value'].iloc[-1],\n",
    "        'Total_Return': performance_metrics['Total Return'],\n",
    "        'Annualized_Return': performance_metrics['Annualized Return'],\n",
    "        'Max_Drawdown': performance_metrics['Max Drawdown']\n",
    "    },\n",
    "    'Risk_Metrics': {\n",
    "        'Sharpe_Ratio': sharpe_ratio,\n",
    "        'Sortino_Ratio': sortino_ratio,\n",
    "        'Calmar_Ratio': calmar_ratio,\n",
    "        'VaR_95': risk_metrics['VaR_95'],\n",
    "        'Expected_Shortfall_95': risk_metrics['ES_95'],\n",
    "        'Skewness': risk_metrics['Skewness'],\n",
    "        'Kurtosis': risk_metrics['Kurtosis']\n",
    "    },\n",
    "    'Trading_Statistics': {\n",
    "        'Win_Rate': win_rate,\n",
    "        'Average_Daily_Return': returns_series.mean(),\n",
    "        'Return_Volatility': returns_series.std(),\n",
    "        'Best_Day': returns_series.max(),\n",
    "        'Worst_Day': returns_series.min(),\n",
    "        'Positive_Days': (returns_series > 0).sum(),\n",
    "        'Negative_Days': (returns_series < 0).sum(),\n",
    "        'Annual_Turnover': annual_turnover\n",
    "    },\n",
    "    'Cost_Analysis': cost_impact_metrics\n",
    "}\n",
    "\n",
    "# Display final report\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STATISTICAL ARBITRAGE STRATEGY - FINAL PERFORMANCE REPORT\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for section, metrics in final_report.items():\n",
    "    print(f\"\\n{section.replace('_', ' ').upper()}:\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    for metric, value in metrics.items():\n",
    "        metric_name = metric.replace('_', ' ')\n",
    "        if isinstance(value, float):\n",
    "            if any(keyword in metric.lower() for keyword in ['return', 'ratio', 'rate', 'impact']):\n",
    "                if abs(value) < 0.001:\n",
    "                    print(f\"{metric_name}: {value:.6f}\")\n",
    "                elif abs(value) < 1:\n",
    "                    print(f\"{metric_name}: {value:.4f}\")\n",
    "                else:\n",
    "                    print(f\"{metric_name}: {value:.2f}\")\n",
    "            elif 'drawdown' in metric.lower() or 'var' in metric.lower():\n",
    "                print(f\"{metric_name}: {value:.4f} ({value:.2%})\")\n",
    "            elif 'value' in metric.lower() or 'capital' in metric.lower():\n",
    "                print(f\"{metric_name}: ${value:,.2f}\")\n",
    "            else:\n",
    "                print(f\"{metric_name}: {value:.4f}\")\n",
    "        else:\n",
    "            print(f\"{metric_name}: {value}\")\n",
    "\n",
    "# Save results to files\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(\"SAVING RESULTS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Create results directory if it doesn't exist\n",
    "results_dir = \"../results\"\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "# Save key datasets\n",
    "datasets_to_save = {\n",
    "    'portfolio_returns.csv': returns_series,\n",
    "    'portfolio_positions.csv': portfolio_positions,\n",
    "    'signals.csv': signals,\n",
    "    'backtest_results.csv': portfolio_backtest,\n",
    "    'performance_metrics.csv': pd.Series(performance_metrics),\n",
    "    'risk_metrics.csv': pd.Series(risk_metrics)\n",
    "}\n",
    "\n",
    "for filename, data in datasets_to_save.items():\n",
    "    filepath = os.path.join(results_dir, filename)\n",
    "    if isinstance(data, pd.DataFrame):\n",
    "        data.to_csv(filepath)\n",
    "    elif isinstance(data, pd.Series):\n",
    "        data.to_csv(filepath, header=True)\n",
    "    print(f\"✓ Saved {filename}\")\n",
    "\n",
    "# Save comprehensive report as YAML\n",
    "report_filepath = os.path.join(results_dir, 'final_performance_report.yaml')\n",
    "with open(report_filepath, 'w') as f:\n",
    "    yaml.dump(final_report, f, default_flow_style=False)\n",
    "print(f\"✓ Saved final_performance_report.yaml\")\n",
    "\n",
    "# Save strategy configuration\n",
    "strategy_filepath = os.path.join(results_dir, 'strategy_config.yaml')\n",
    "with open(strategy_filepath, 'w') as f:\n",
    "    yaml.dump(config, f, default_flow_style=False)\n",
    "print(f\"✓ Saved strategy_config.yaml\")\n",
    "\n",
    "print(f\"\\nAll results saved to: {results_dir}\")\n",
    "\n",
    "# Generate executive summary\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"EXECUTIVE SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "total_return_pct = performance_metrics['Total Return']\n",
    "annual_return_pct = performance_metrics['Annualized Return']\n",
    "max_dd_pct = performance_metrics['Max Drawdown']\n",
    "\n",
    "print(f\"\"\"\n",
    "📊 STRATEGY PERFORMANCE OVERVIEW:\n",
    "   • Strategy delivered {total_return_pct:.1%} total return over the backtest period\n",
    "   • Annualized return of {annual_return_pct:.1%} with maximum drawdown of {max_dd_pct:.1%}\n",
    "   • Sharpe ratio of {sharpe_ratio:.2f} indicates {('strong' if sharpe_ratio > 1 else 'moderate' if sharpe_ratio > 0.5 else 'weak')} risk-adjusted performance\n",
    "\n",
    "⚡ SIGNAL EFFECTIVENESS:\n",
    "   • Generated {signal_summary['Long_signals'].sum() + signal_summary['Short_signals'].sum()} total signals\n",
    "   • Win rate of {win_rate:.1%} with average winning day of {positive_returns.mean():.2%}\n",
    "   • Signal frequency averaged {signal_summary['Signal_frequency'].mean():.1%} across all assets\n",
    "\n",
    "💰 COST IMPACT:\n",
    "   • Transaction costs reduced returns by {cost_impact_metrics['Cost_Impact_on_Returns']:.2%} annually\n",
    "   • Annual turnover of {annual_turnover:.1f}x indicates {('high' if annual_turnover > 3 else 'moderate' if annual_turnover > 1 else 'low')} trading frequency\n",
    "\n",
    "🎯 RISK MANAGEMENT:\n",
    "   • 95% VaR of {risk_metrics['VaR_95']:.2%} indicates daily loss threshold\n",
    "   • {\"Positive\" if risk_metrics['Skewness'] > 0 else \"Negative\"} skew of {risk_metrics['Skewness']:.2f} shows return distribution characteristics\n",
    "   • Maximum consecutive losses: {risk_metrics['Max_Consecutive_Losses']} days\n",
    "\n",
    "✅ RECOMMENDATION: \n",
    "   Strategy shows {\"promising\" if sharpe_ratio > 1 and max_dd_pct > -0.2 else \"mixed\"} results with room for optimization in \n",
    "   {\"signal generation\" if win_rate < 0.55 else \"cost management\" if annual_turnover > 3 else \"risk management\"}.\n",
    "\"\"\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"BACKTEST ANALYSIS COMPLETE!\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
